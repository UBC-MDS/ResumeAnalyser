{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "To use `resumeanalyser` in a project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resumeanalyser\n",
    "print(resumeanalyser.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage of Text Extraction Functions\n",
    "\n",
    "`resumeanalyser` allows you to read in text from PDF or docx documents, which are the formats many resumes come in. We will be using the simple text file stores in the tests/data directory of this project repository to demonstrate how these functions work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from docx documents\n",
    "The function `docx_to_text` allows you to extract text from Word documents and store the text as a string. It takes in a path name ending in `.docx` as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_reading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in text from Word document\n",
    "simple_docx_path = \"../tests/data/simple_text.docx\"\n",
    "sample_docx_text = docx_to_text(simple_docx_path)\n",
    "print(sample_docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from PDF documents\n",
    "Similarly, the function `pdf_to_text` allows you to extract text from PDF documents and store the text as a string. It takes in a path name ending in `.pdf` as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in text from PDF document\n",
    "simple_pdf_path = \"../tests/data/simple_text_pdf.pdf\"\n",
    "sample_pdf_text = pdf_to_text(simple_pdf_path)\n",
    "print(sample_pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions are also able to extract text which has been formatted as headings from Word documents, as can be seen here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in fancy formatted text from Word document\n",
    "fancy_docx_path = \"../tests/data/fancy_text_docx.docx\"\n",
    "fancy_sample_docx_text = docx_to_text(fancy_docx_path)\n",
    "print(fancy_sample_docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works for PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in fancy formatted text from PDF document\n",
    "fancy_pdf_path = \"../tests/data/fancy_text_pdf.pdf\"\n",
    "fancy_sample_pdf_text = pdf_to_text(fancy_pdf_path)\n",
    "print(fancy_sample_pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage of Text Cleaning Functions\n",
    "\n",
    "`resumeanalyser` offers how to use a series of text cleaning functions. These functions include:\n",
    "1. Removing punctuation\n",
    "2. Tokenization\n",
    "3. Converting to lower case\n",
    "4. Removing stop words\n",
    "5. Lemmatization\n",
    "\n",
    "You can apply these functions either step-by-step to understand each part of the text cleaning process, \n",
    "or you can use the `clean_text` function to apply all these steps in one go for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "sample_text = \"The cats are chasing the mice, and one mouse is running faster than the others.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating step-by-step process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove punctuation\n",
    "no_punctuation = remove_punctuation(sample_text)\n",
    "print(\"Text without Punctuation:\", no_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenize the text\n",
    "tokens = tokenize(no_punctuation)\n",
    "print(\"Tokenized Text:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert to lower case\n",
    "lower_tokens = to_lower(tokens)\n",
    "print(\"Lowercase Tokens:\", lower_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove stop words\n",
    "no_stop_words = remove_stop_words(lower_tokens)\n",
    "print(\"Tokens without Stop Words:\", no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Lemmatize\n",
    "lemmatized_tokens = lemmatize(no_stop_words)\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the clean_text function for an all-in-one solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_cleaning import clean_text\n",
    "cleaned_text = clean_text(sample_text)\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage of Metric Functions for Comparing two texts\n",
    "\n",
    "`resumeanalyser` offers two functions to compare the two texts provided by the user. These functions include:\n",
    "1. Keyword Matching Score\n",
    "2. Semantic Text Matching Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Matching Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It typically refers to a measure of how closely two pieces of text align in a character-by-character or word-by-word manner without considering variations or synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literal Match Score: 25.82\n"
     ]
    }
   ],
   "source": [
    "from resumeanalyser.metrics import SimilarityCV\n",
    "\n",
    "literal_match_score = SimilarityCV(\"I am studying Data Science at UBC\", \"There are many good sources to study Data Science online\")\n",
    "print(\"Literal Match Score:\", literal_match_score, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Text Matching Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It measures the similarity in meaning between two pieces of text. Unlike literal or exact match scores, semantic matching takes into account the context, synonyms, and related concepts to determine how closely the content aligns in terms of intent or significance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'en_core_web_md' model...\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "Syntactic Match Score: 39.45 %\n"
     ]
    }
   ],
   "source": [
    "from resumeanalyser.metrics import SimilaritySpacy\n",
    "\n",
    "semantic_match_score = SimilaritySpacy(\"I am studying Data Science at UBC\", \"There are many good sources to study Data Science online\")\n",
    "print(\"Syntactic Match Score:\", round(semantic_match_score*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Using Plotting Functions of the Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = 'I am going to fill in a test text here the the the a a a a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can plot the word cloud of the input resume/job description text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plot_wordcloud(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or plot the top-frenquency words that are most relvant in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plot_topwords(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to plot both in one suite plot for illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plot_suite(test_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
