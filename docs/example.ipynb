{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "To use `resumeanalyser` in a project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resumeanalyser\n",
    "print(resumeanalyser.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage of Text Extraction Functions\n",
    "\n",
    "`resumeanalyser` allows you to read in text from PDF or docx documents, which are the formats many resumes come in. We will be using the simple text file stores in the tests/data directory of this project repository to demonstrate how these functions work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from docx documents\n",
    "The function `docx_to_text` allows you to extract text from Word documents and store the text as a string. It takes in a path name ending in `.docx` as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_reading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in text from Word document\n",
    "simple_docx_path = \"../tests/data/simple_text.docx\"\n",
    "sample_docx_text = docx_to_text(simple_docx_path)\n",
    "print(sample_docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from PDF documents\n",
    "Similarly, the function `pdf_to_text` allows you to extract text from PDF documents and store the text as a string. It takes in a path name ending in `.pdf` as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in text from PDF document\n",
    "simple_pdf_path = \"../tests/data/simple_text_pdf.pdf\"\n",
    "sample_pdf_text = pdf_to_text(simple_pdf_path)\n",
    "print(sample_pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions are also able to extract text which has been formatted as headings from Word documents, as can be seen here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in fancy formatted text from Word document\n",
    "fancy_docx_path = \"../tests/data/fancy_text_docx.docx\"\n",
    "fancy_sample_docx_text = docx_to_text(fancy_docx_path)\n",
    "print(fancy_sample_docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works for PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in fancy formatted text from PDF document\n",
    "fancy_pdf_path = \"../tests/data/fancy_text_pdf.pdf\"\n",
    "fancy_sample_pdf_text = pdf_to_text(fancy_pdf_path)\n",
    "print(fancy_sample_pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage of Text Cleaning Functions\n",
    "\n",
    "`resumeanalyser` offers how to use a series of text cleaning functions. These functions include:\n",
    "1. Removing punctuation\n",
    "2. Tokenization\n",
    "3. Converting to lower case\n",
    "4. Removing stop words\n",
    "5. Lemmatization\n",
    "\n",
    "You can apply these functions either step-by-step to understand each part of the text cleaning process, \n",
    "or you can use the `clean_text` function to apply all these steps in one go for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "sample_text = \"The cats are chasing the mice, and one mouse is running faster than the others.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating step-by-step process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove punctuation\n",
    "no_punctuation = remove_punctuation(sample_text)\n",
    "print(\"Text without Punctuation:\", no_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenize the text\n",
    "tokens = tokenize(no_punctuation)\n",
    "print(\"Tokenized Text:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert to lower case\n",
    "lower_tokens = to_lower(tokens)\n",
    "print(\"Lowercase Tokens:\", lower_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove stop words\n",
    "no_stop_words = remove_stop_words(lower_tokens)\n",
    "print(\"Tokens without Stop Words:\", no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Lemmatize\n",
    "lemmatized_tokens = lemmatize(no_stop_words)\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the clean_text function for an all-in-one solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_cleaning import clean_text\n",
    "cleaned_text = clean_text(sample_text)\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Using Plotting Functions of the Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = 'I am going to fill in a test text here the the the a a a a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can plot the word cloud of the input resume/job description text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plot_wordcloud(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or plot the top-frenquency words that are most relvant in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plot_topwords(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to plot both in one suite plot for illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plot_suite(test_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
