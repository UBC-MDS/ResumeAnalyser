{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "To use `resumeanalyser` in a project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n"
     ]
    }
   ],
   "source": [
    "import resumeanalyser\n",
    "print(resumeanalyser.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage of Text Cleaning Functions\n",
    "\n",
    "`resumeanalyser` offers how to use a series of text cleaning functions. These functions include:\n",
    "1. Removing punctuation\n",
    "2. Tokenization\n",
    "3. Converting to lower case\n",
    "4. Removing stop words\n",
    "5. Lemmatization\n",
    "\n",
    "You can apply these functions either step-by-step to understand each part of the text cleaning process, \n",
    "or you can use the `clean_text` function to apply all these steps in one go for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resumeanalyser.text_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "sample_text = \"The cats are chasing the mice, and one mouse is running faster than the others.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating step-by-step process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without Punctuation: The cats are chasing the mice and one mouse is running faster than the others\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove punctuation\n",
    "no_punctuation = remove_punctuation(sample_text)\n",
    "print(\"Text without Punctuation:\", no_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: ['The', 'cats', 'are', 'chasing', 'the', 'mice', 'and', 'one', 'mouse', 'is', 'running', 'faster', 'than', 'the', 'others']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize the text\n",
    "tokens = tokenize(no_punctuation)\n",
    "print(\"Tokenized Text:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase Tokens: ['the', 'cats', 'are', 'chasing', 'the', 'mice', 'and', 'one', 'mouse', 'is', 'running', 'faster', 'than', 'the', 'others']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Convert to lower case\n",
    "lower_tokens = to_lower(tokens)\n",
    "print(\"Lowercase Tokens:\", lower_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens without Stop Words: ['cats', 'chasing', 'mice', 'one', 'mouse', 'running', 'faster', 'others']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Remove stop words\n",
    "no_stop_words = remove_stop_words(lower_tokens)\n",
    "print(\"Tokens without Stop Words:\", no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Tokens: ['cat', 'chasing', 'mouse', 'one', 'mouse', 'running', 'faster', 'others']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Lemmatize\n",
    "lemmatized_tokens = lemmatize(no_stop_words)\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the clean_text function for an all-in-one solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: cat chasing mouse one mouse running faster others\n"
     ]
    }
   ],
   "source": [
    "from resumeanalyser.text_cleaning import clean_text\n",
    "cleaned_text = clean_text(sample_text)\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
